<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chatbot Arena Leaderboard Updates (Week 2) | Chatbot Arena </title> <meta name="author" content="Chatbot Arena"> <meta name="description" content="an open platform for human preference evaluations"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/bear.png?23fade998cf650fe43c0a84f33581251"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lmarena.github.io/blog/2023/leaderboard-week2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Chatbot Arena Leaderboard Updates (Week 2)",
            "description": "",
            "published": "May 10, 2023",
            "authors": [
              
              {
                "author": "Chatbot Arena Team",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "LMSYS Org",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title" href="/"> <span class="font-weight-bold">Chatbot</span> Arena </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/about/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Chatbot Arena Leaderboard Updates (Week 2)</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <p>We release an updated leaderboard with more models and new data we collected last week, after the announcement of the anonymous <a href="https://blog.lmarena.ai/blog/2023/arena/" rel="external nofollow noopener" target="_blank">Chatbot Arena</a>. We are actively iterating on the design of the arena and leaderboard scores.</p> <p>In this update, we have added 4 new yet strong players into the Arena, including three <strong>proprietary models</strong> and one open-source model. They are:</p> <ul> <li>OpenAI GPT-4</li> <li>OpenAI GPT-3.5-turbo</li> <li>Anthropic Claude-v1</li> <li>RWKV-4-Raven-14B</li> </ul> <p>Table 1 displays the Elo ratings of all 13 models, which are based on the 13K voting data and calculations shared in this <a href="https://colab.research.google.com/drive/1RAWb22-PFNI-X1gPVzc927SGUdfr6nsR?usp=sharing" rel="external nofollow noopener" target="_blank">notebook</a>. You can also try the voting <a href="https://lmarena.ai" rel="external nofollow noopener" target="_blank">demo</a>.</p> <style>th{text-align:left}td{text-align:left}</style> <p style="color:gray; text-align: center;">Table 1. LLM Leaderboard (April 24 - May 8, 2023). The latest and detailed version <a href="https://lmarena.ai/?leaderboard" target="_blank" rel="external nofollow noopener">here</a>.</p> <table style="display: flex; justify-content: center;" align="left"> <tbody> <tr> <th>Rank</th> <th>Model</th> <th>Elo Rating</th> <th>Description</th> <th>License</th> </tr> <tr> <td>1</td> <td>ðŸ¥‡ <a href="https://chat.openai.com/" target="_blank" rel="external nofollow noopener">GPT-4</a> </td> <td>1274</td> <td>ChatGPT-4 by OpenAI</td> <td>Proprietary</td> </tr> <tr> <td>2</td> <td>ðŸ¥ˆ <a href="https://www.anthropic.com/index/introducing-claude" target="_blank" rel="external nofollow noopener">Claude-v1</a> </td> <td>1224</td> <td>Claude by Anthropic</td> <td>Proprietary</td> </tr> <tr> <td>3</td> <td>ðŸ¥‰ <a href="https://chat.openai.com/" target="_blank" rel="external nofollow noopener">GPT-3.5-turbo</a> </td> <td>1155</td> <td>ChatGPT-3.5 by OpenAI</td> <td>Proprietary</td> </tr> <tr> <td>4</td> <td><a href="https://lmsys.org/blog/2023-03-30-vicuna/" target="_blank" rel="external nofollow noopener">Vicuna-13B</a></td> <td>1083</td> <td>a chat assistant fine-tuned from LLaMA on user-shared conversations by LMSYS</td> <td>Weights available; Non-commercial</td> </tr> <tr> <td>5</td> <td><a href="https://bair.berkeley.edu/blog/2023/04/03/koala" target="_blank" rel="external nofollow noopener">Koala-13B</a></td> <td>1022</td> <td>a dialogue model for academic research by BAIR</td> <td>Weights available; Non-commercial</td> </tr> <tr> <td>6</td> <td><a href="https://huggingface.co/BlinkDL/rwkv-4-raven" target="_blank" rel="external nofollow noopener">RWKV-4-Raven-14B</a></td> <td>989</td> <td>an RNN with transformer-level LLM performance</td> <td>Apache 2.0</td> </tr> <tr> <td>7</td> <td><a href="https://open-assistant.io" target="_blank" rel="external nofollow noopener">Oasst-Pythia-12B</a></td> <td>928</td> <td>an Open Assistant for everyone by LAION</td> <td>Apache 2.0</td> </tr> <tr> <td>8</td> <td><a href="https://chatglm.cn/blog" target="_blank" rel="external nofollow noopener">ChatGLM-6B</a></td> <td>918</td> <td>an open bilingual dialogue language model by Tsinghua University</td> <td>Weights available; Non-commercial</td> </tr> <tr> <td>9</td> <td><a href="https://github.com/stability-AI/stableLM" target="_blank" rel="external nofollow noopener">StableLM-Tuned-Alpha-7B</a></td> <td>906</td> <td>Stability AI language models</td> <td>CC-BY-NC-SA-4.0</td> </tr> <tr> <td>10</td> <td><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" target="_blank" rel="external nofollow noopener">Alpaca-13B</a></td> <td>904</td> <td>a model fine-tuned from LLaMA on instruction-following demonstrations by Stanford</td> <td>Weights available; Non-commercial</td> </tr> <tr> <td>11</td> <td><a href="https://huggingface.co/lmsys/fastchat-t5-3b-v1.0" target="_blank" rel="external nofollow noopener">FastChat-T5-3B</a></td> <td>902</td> <td>a chat assistant fine-tuned from FLAN-T5 by LMSYS</td> <td>Apache 2.0</td> </tr> <tr> <td>12</td> <td><a href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" target="_blank" rel="external nofollow noopener">Dolly-V2-12B</a></td> <td>863</td> <td>an instruction-tuned open large language model by Databricks</td> <td>MIT</td> </tr> <tr> <td>13</td> <td><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="external nofollow noopener">LLaMA-13B</a></td> <td>826</td> <td>open and efficient foundation language models by Meta</td> <td>Weights available; Non-commercial</td> </tr> </tbody> </table> <p>If you want to see more models, please help us <a href="https://github.com/lm-sys/FastChat/blob/main/docs/arena.md#how-to-add-a-new-model" rel="external nofollow noopener" target="_blank">add them</a> or <a href="mailto:lmsysorg@gmail.com">contact us</a> by giving us API access.</p> <h2 id="overview">Overview</h2> <p>Thanks to the communityâ€™s help, we have gathered 13k anonymous votes. Looking at the rankings and data collected from this leaderboard update, we have a few interesting findings.</p> <p><strong>Gaps between proprietary and open-source models</strong><br> We do observe a substantial gap between the three proprietary models and all other open-source models. In particular, GPT-4 is leading the board, achieving an Elo score of 1274. It is almost 200 scores higher than the best open-source alternative on this board â€“ our Vicuna-13B. After dropping ties, GPT-4 wins 82% of the matches when it is against Vicuna-13B, and it even wins 79% of the matches when it is against its previous generation GPT-3.5-turbo.</p> <p>However, it is important to note that these open-source models on the leaderboard generally have fewer parameters, in the range of 3B - 14B, than proprietary models. In fact, recent advancements in LLMs and data curation have allowed for significant improvements in performance with smaller models. <a href="https://ai.google/discover/palm2" rel="external nofollow noopener" target="_blank">Googleâ€™s latest PaLM 2</a> is a great example of this: knowing that PaLM 2 achieves even better performance than its previous generation using smaller model sizes, we remain very optimistic about the potential for open-source language models to catch up. Through our <a href="https://github.com/lm-sys/FastChat" rel="external nofollow noopener" target="_blank">FastChat-based Chatbot Arena</a> and this leaderboard effort, we hope to contribute a trusted evaluation platform for evaluating LLMs, and help advance this field and create better language models for everyone.</p> <p><strong>Comparing proprietary models</strong><br> However, among the three proprietary models, we do observe, based on our collected voting results, that Anthropicâ€™s Claude model is preferred by our users over GPT-3.5-turbo, which is often discussed as its opponent. In fact, Claude is highly competitive even when competing against the most powerful model â€“ OpenAIâ€™s GPT-4. Looking at the win rate plots (Figure 3 below), among the 66 non-tied matches between GPT-4 and Claude, Claude indeed wins over GPT-4 in 32 (48%) matches. Great job Anthropic team!</p> <p><strong>Comparing open-source chatbots</strong><br> In this update, we have added RWKV-4-Raven-14B model into the Arena thanks to the community <a href="https://github.com/lm-sys/FastChat/issues/633" rel="external nofollow noopener" target="_blank">contribution</a>. Unlike all other models, RWKV model is an RNN instead of a transformer-based model; but it performs surprisingly well! It soon uptrends on the leaderboard and is positioned #6 on the overall leaderboard. It wins more than 50% of non-tied matches against all other open-source models except Vicuna. You are welcome to check out its <a href="https://github.com/BlinkDL/RWKV-LM" rel="external nofollow noopener" target="_blank">repo</a> to learn more about other features like memory saving and fast inference. Kudos to the RWKV developers.</p> <p><strong>Fluctuations of Elo scores</strong><br> The Elo scores of existing models can go up and down depending on the results of the new games played. This is similar to the way the Elo scores of chess players vary over time (see <a href="https://en.chessbase.com/post/historical-chess-ratings-dynamically-presented" rel="external nofollow noopener" target="_blank">here</a>). Since the participation of the three strong proprietary models, the Chatbot Arena has never been more competitive than ever before! As a consequence, we observe the Elo scores of all open source models have decreased a bit. This is because open source models lose lots of pairwise matches when they are against the proprietary models.</p> <h2 id="detailed-results">Detailed Results</h2> <p><strong>When does GPT-4 fail?</strong><br> We present a few examples in which GPT-4 is not preferred by users.</p> <p><img src="/assets/img/blog/leaderboard_week2/claude_vs_gpt4.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto;" width="90%"></p> <p style="color:gray; text-align: center;">Figure 1: One example where Claude is preferred over GPT-4.</p> <p>In Figure 1, the user posed a tricky question that demanded careful reasoning and planning. Although both Claude and GPT-4 provided similar answers, Claudeâ€™s response was marginally better as the needle was positioned on top. However, we observed that the outcome of this example cannot always be replicated due to the randomness of sampling. Sometimes GPT-4 can also give the same order as Claude, but it fails at this generation trial. Additionally, we noted that the behavior of GPT-4 differed slightly when using the OpenAI API versus the ChatGPT interface, which could be attributed to different prompts, sampling parameters, or other unknown factors.</p> <p><img src="/assets/img/blog/leaderboard_week2/claude_vs_gpt4_fail.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto;" width="90%"></p> <p style="color:gray; text-align: center;">Figure 2: One example where a user thinks both Claude and GPT-4 are wrong.</p> <p>In Figure 2, both Claude and GPT-4 are still struggling with this kind of tricky reasoning questions despite their amazing capabilities.</p> <p>Besides these tricky cases, there are also a lot of easy questions that do not require complex reasoning or knowledge. In this case, open source models like Vicuna can perform on par with GPT-4, so we might be able to use a slightly weaker (but smaller or cheaper) LLM in place of the more powerful one like GPT-4.</p> <p><strong>Win Fraction Matrix</strong><br> We present the win fraction of all model pairs in Figure 3. <img src="/assets/img/blog/leaderboard_week2/win_fraction_matrix.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto;" width="90%"></p> <p style="color:gray; text-align: center;">Figure 3: Fraction of Model A Wins for All Non-tied A vs. B Battles.</p> <p><strong>Language-specific leaderboards</strong><br> Lastly, we present two language-specific leaderboards, by isolating the conversation data into two subsets based on the language: (1) English-only and (2) non-English. From Figure 4, we can tell that Koala is worse at non-English languages and ChatGLM-6B is better at non-English languages. This is because of the different compositions of their training data.</p> <p><img src="/assets/img/blog/leaderboard_week2/english_vs_non_english.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto;" width="90%"></p> <p style="color:gray; text-align: center;">Figure 4: The English-only and non-English leaderboards.</p> <p>More figures, analyses, and calculations can be found in this <a href="https://colab.research.google.com/drive/1RAWb22-PFNI-X1gPVzc927SGUdfr6nsR?usp=sharing" rel="external nofollow noopener" target="_blank">notebook</a>.</p> <h2 id="next-steps">Next Steps</h2> <p><strong>Help us add more models</strong><br> Since the launch of Chatbot Arena, we have seen growing interest from the community. Many model developers are eager to put their chatbots into the Arena and see how they perform against others. Please help us add more models by following <a href="https://github.com/lm-sys/FastChat/blob/main/docs/arena.md#how-to-add-a-new-model" rel="external nofollow noopener" target="_blank">this guide</a>.</p> <p><strong>Bring your own self-hosted chatbot (BYOC)</strong><br> We also plan to open some APIs to allow competitors to register their self-hosted chatbots and participate in the Arena.</p> <p><strong>Area-specific Arena</strong><br> Similar to the language-specific Arena, we will extend a single, monolithic leaderboard to more areas, and publish more functionality-specific leaderboards, such as writing, coding, and reasoning. In which specific area or ability do you want to see the LLMs evaluated? Please give us feedback on <a href="https://discord.gg/HSWAKCrnFx" rel="external nofollow noopener" target="_blank">Discord</a> or <a href="https://twitter.com/lmsysorg" rel="external nofollow noopener" target="_blank">Twitter</a>.</p> <h2 id="acknowledgement">Acknowledgement</h2> <p>This blog post is primarily contributed by Lianmin Zheng, Ying Sheng, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. We thank other members of LMSYS team (Wei-Lin Chiang, Siyuan Zhuang, and more) for valuable feedback and MBZUAI for donating compute resources. Additionally, we extend our thanks to community contributors for their votes and model support.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"lmarena/lmarena.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2024 Chatbot Arena. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-",title:"",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-about",title:"about",description:"",section:"Navigation",handler:()=>{window.location.href="/about/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-copilot-arena",title:"Copilot Arena",description:"Copilot Arena&#39;s Initial Leaderboard, Insights, and a New Prompting Method for Code Completions",section:"Posts",handler:()=>{window.location.href="/blog/2024/copilot-arena/"}},{id:"post-chatbot-arena-categories",title:"Chatbot Arena Categories",description:"Definitions, Methods, and Insights",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-category/"}},{id:"post-preference-proxy-evaluations",title:"Preference Proxy Evaluations",description:"A New Benchmark for Evaluating Reward Models and LLM Judges",section:"Posts",handler:()=>{window.location.href="/blog/2024/preference-proxy-evaluations/"}},{id:"post-agent-arena",title:"Agent Arena",description:"A Platform for Evaluating and Comparing LLM Agents Across Models, Tools, and Frameworks",section:"Posts",handler:()=>{window.location.href="/blog/2024/agent-arena/"}},{id:"post-statistical-extensions-of-the-bradley-terry-and-elo-models",title:"Statistical Extensions of the Bradley-Terry and Elo Models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/extended-arena/"}},{id:"post-chatbot-arena-new-blog",title:"Chatbot Arena New Blog",description:"A new chapter for Chatbot Arena!",section:"Posts",handler:()=>{window.location.href="/blog/2024/new-site/"}},{id:"post-redteam-arena",title:"RedTeam Arena",description:"An Open-Source, Community-driven Jailbreaking Platform",section:"Posts",handler:()=>{window.location.href="/blog/2024/redteam-arena/"}},{id:"post-does-style-matter",title:"Does Style Matter?",description:"Disentangling style and substance in Chatbot Arena",section:"Posts",handler:()=>{window.location.href="/blog/2024/style-control/"}},{id:"post-the-multimodal-arena-is-here",title:"The Multimodal Arena is Here!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/multimodal/"}},{id:"post-introducing-hard-prompts-category-in-chatbot-arena",title:"Introducing Hard Prompts Category in Chatbot Arena",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/hard-prompts/"}},{id:"post-what-39-s-up-with-llama-3-arena-data-analysis",title:"What&#39;s up with Llama 3? Arena data analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/llama3/"}},{id:"post-lmsys-chatbot-arena-kaggle-competition",title:"LMSYS Chatbot Arena Kaggle Competition",description:"Predicting Human Preference with $100,000 in Prizes",section:"Posts",handler:()=>{window.location.href="/blog/2024/kaggle-competition/"}},{id:"post-from-live-data-to-high-quality-benchmarks-the-arena-hard-pipeline",title:"From Live Data to High-Quality Benchmarks - The Arena-Hard Pipeline",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-hard/"}},{id:"post-chatbot-arena-policy-update",title:"Chatbot Arena Policy Update",description:"Live and Community-Driven LLM Evaluation",section:"Posts",handler:()=>{window.location.href="/blog/2024/policy/"}},{id:"post-chatbot-arena-new-models-amp-elo-system-update",title:"Chatbot Arena - New models &amp; Elo system update",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-elo-update/"}},{id:"post-catch-me-if-you-can-how-to-beat-gpt-4-with-a-13b-model",title:"Catch me if you can! How to beat GPT-4 with a 13B model...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/llm-decontaminator/"}},{id:"post-chatbot-arena-conversation-dataset-release",title:"Chatbot Arena Conversation Dataset Release",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/dataset/"}},{id:"post-chatbot-arena-leaderboard-updates-week-8",title:"Chatbot Arena Leaderboard Updates (Week 8)",description:"Introducing MT-Bench and Vicuna-33B",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week8/"}},{id:"post-chatbot-arena-leaderboard-updates-week-4",title:"Chatbot Arena Leaderboard Updates (Week 4)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week4/"}},{id:"post-chatbot-arena-leaderboard-updates-week-2",title:"Chatbot Arena Leaderboard Updates (Week 2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week2/"}},{id:"post-chatbot-arena",title:"Chatbot Arena",description:"Benchmarking LLMs in the Wild with Elo Ratings",section:"Posts",handler:()=>{window.location.href="/blog/2023/arena/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%6D%61%72%65%6E%61.%61%69@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>