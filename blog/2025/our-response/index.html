<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Our Response to 'The Leaderboard Illusion' Writeup | LM Arena </title> <meta name="author" content="LM Arena"> <meta name="description" content="an open platform for human preference evaluations"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/vicuna.jpeg?101e2cca9da6907c55807adf8b3b38b7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lmarena.github.io/blog/2025/our-response/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Our Response to 'The Leaderboard Illusion' Writeup",
            "description": "",
            "published": "May 09, 2025",
            "authors": [
              
              {
                "author": "LMArena Team",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "LMArena",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title" href="/"> <span class="font-weight-bold">LM</span> Arena </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/about/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Our Response to 'The Leaderboard Illusion' Writeup</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <p>Recently, a writeup titled “The Leaderboard Illusion” has been circulating with several claims and recommendations about the Chatbot Arena leaderboard. We are grateful for the feedback and have plans to improve Chatbot Arena as a result of our ongoing discussions with the authors.</p> <p><strong>Arena’s mission is to provide truthful and scientific evaluation of models across diverse domains, grounded in real-world uses.</strong> This guiding principle shapes how we design our systems and policies to support the AI research and development community. Clear communication and shared understanding help move the field forward, and we’re committed to being active, thoughtful contributors to that effort. As such, we always welcome the opportunity to bring more transparency into how the platform works and what could be improved. There are thoughtful points and recommendations raised in the writeup that are quite constructive, and we’re actively considering them as part of our ongoing work.</p> <p>To begin, we are excited to address some of the recommendations raised in the writeup head on. Here is an outline of our preliminary plans:</p> <ul> <li> <p style="font-weight: 400;">Since March 2024, <a href="https://blog.lmarena.ai/blog/2024/policy/" rel="external nofollow noopener" target="_blank">our policy</a> has established rules for pre-release testing. In a future policy release, we will explicitly state that model providers are all allowed to test multiple variants of their models pre-release, subject to our system's constraints.</p> </li> <li> <p style="font-weight: 400;">We will increase clarity about how models are retired from battle mode and explicitly mark which models are retired.</p> </li> <li> <p style="font-weight: 400;">Previously, we announced pre-release-tested models on the leaderboard after 2,000 votes had been accumulated since the beginning of testing. While the selection bias vanishes rapidly due to continuous testing with fresh user feedback, we will mark model scores as "provisional" until additional 2,000 fresh votes have been collected after model release, if more than 10 models were pre-release tested in parallel.</p> </li> </ul> <p>While we welcome feedback and open discussion, the piece also contains several incorrect claims. We believe it’s important to address these points of factual disagreement directly. Our goal is not to criticize, but to help strengthen the reliability of AI evaluations. Rather than seeing these critiques as conflict, we see it as an opportunity for collaboration: a chance to clarify our approach, share data and learn together to help paint a fuller picture for analysis.</p> <p>Below is a breakdown of the factual concerns we identified that affect the claims in the paper. We have been in active and productive conversation with the authors about these concerns, have shared these directly with them, and are working together to amend the claims in the paper: <img src="/assets/img/blog/our_response/response-1.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: Open source models represent 8.8% on the leaderboard, implying proprietary models benefit most.</p> </li> <li> <p style="font-weight: 400;">Truth: Official <a href="https://topic.lmarena.ai/blog/2025/our-response/" rel="external nofollow noopener" target="_blank">Chatbot Arena stats</a> (published 2025/4/27) show <b>Open Models at 40.9%</b>. The writeup’s calculation is missing open-weight models (e.g., Llama, Gemma), significantly undercounting the open models.</p> </li> </ul> <p><img src="/assets/img/blog/our_response/response-2.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: Pre-release testing can boost Arena Score by 100+ points.</p> </li> <li> <p style="font-weight: 400;">Truth: The numbers in the original plot are <b>unrelated to Chatbot Arena</b>. The plot is a simulation - using <b>Gaussians</b> with mean 1200 and an arbitrarily chosen variance to illustrate their argument. It plots the maximum as the number of Gaussians grows. The larger the number of Gaussians, the larger is their maximum, and the numerical value is driven by the variance (arbitrarily chosen by authors), not by anything in Chatbot Arena's policies or actual performance. </p> </li> <li> <p style="font-weight: 400;">Truth: <b>Boosts in a model’s score due to pre-release testing are minimal.</b> Because Arena is constantly collecting <b><a href="https://blog.lmarena.ai/blog/2025/freshness/" rel="external nofollow noopener" target="_blank">fresh data</a> from new users</b>, selection bias quickly goes to zero. Our analysis shows the effect of pre-release testing is smaller than claimed with finite data (around +11 Elo after 50 tests and 3000 votes) and diminishes to zero as fresh evaluation data accumulates. The "claimed effect" is a significant overstatement of the "true effect” under the Bradley-Terry model. See further technical analysis <a href="https://docs.google.com/document/d/1j5kEbl5TkRSbtVMdh5uRJSfLHiNjxtmCdGxKh2hnl1Q/edit?tab=t.0" rel="external nofollow noopener" target="_blank">here</a>. </p> </li> <li> <p style="font-weight: 400;">Truth: Any non-trivial boost in Arena score has to come from substantial model improvements. Chatbot Arena helps providers identify their best models, and that is a good thing. A good benchmark should help people find the best model. Both model providers and the community benefit from getting this early feedback.</p> </li> </ul> <p><img src="/assets/img/blog/our_response/response-3.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: Submitting the same model checkpoint can lead to substantially different scores.</p> </li> <li> <p style="font-weight: 400;">Truth: Submitting the same model checkpoint leads to scores within a reasonable confidence interval. In their reporting of their Chatbot Arena results, <b>the confidence intervals are omitted</b>, although we shared them with the authors. <u>There's no evidence that rankings would differ</u>. For the example cited, scores like 1069 (±27) and 1054 (±18/22) have overlapping confidence intervals, meaning the variations are within the expected statistical noise, not indicative of substantially different underlying performance.</p> </li> </ul> <p><img src="/assets/img/blog/our_response/response-4.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: Big labs are given preferential treatment in pre-release testing.</p> </li> <li> <p style="font-weight: 400;">Truth: Models are treated fairly according to our model testing policy -- any model provider can submit as many public and private variants as they would like, as long as we have capacity for it. <b>Larger labs naturally submit more models because they develop more models, but all have access.</b> Also, accounting for vision models as well, we helped Cohere evaluate 9 pre-release models (from 2025/1-present), which is 2-3x more pre-release tests than labs like xAI/OpenAI.</p> </li> </ul> <p><img src="/assets/img/blog/our_response/response-5.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: Chatbot Arena has an "unstated policy" allowing preferential pre-release testing for select providers.</p> </li> <li> <p style="font-weight: 400;">Truth: Chatbot Arena's policy regarding the evaluation of unreleased models has been <b>publicly available for over a year</b>, published on March 1, 2024. There's no secret or unstated policy. It has always been our policy to only publish the results for publicly available models.</p> </li> </ul> <p><img src="/assets/img/blog/our_response/response-6.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Claim: A 112% performance gain can be achieved in Chatbot Arena by incorporating Chatbot Arena data.</p> </li> <li> <p style="font-weight: 400;">Truth: The experiment cited for this gain was conducted on <b>"Arena-Hard," a static benchmark with 500 data points that uses an LLM judge, and no human labels.</b> This is not representative of Chatbot Arena. This claim with respect to Chatbot Arena is not supported by evidence.</p> </li> </ul> <p>Finally, we make one more clarification, which is not meant to be a factual disagreement – just a clarification for those that haven’t read our policy to see how models are sampled.</p> <p><img src="/assets/img/blog/our_response/response-7.png" style="display:block; margin-top: auto; margin-left: auto; margin-right: auto; margin-bottom: auto; width: 95%"></p> <ul> <li> <p style="font-weight: 400;">Clarification: <b>The best models, regardless of provider, are upsampled to improve the user experience.</b> The <a href="https://blog.lmarena.ai/blog/2024/policy/" rel="external nofollow noopener" target="_blank">Arena policy</a> above states how we sample models in battle mode in detail. It so happens that the biggest labs often have multiple of the best models, but as the plot from the writeup shows, we also maintain strong diversity and sample models from other providers as well. See the historical fraction of battles on a per-provider basis on our <a href="https://blog.lmarena.ai/blog/2025/two-year-celebration/" rel="external nofollow noopener" target="_blank">blog</a>.</p> </li> </ul> <p>We stand by the integrity and transparency of the Chatbot Arena platform. We welcome constructive feedback, especially when it helps us all build better tools for the community. However, it’s crucial that such critiques are based on accurate data and a correct understanding of our publicly stated policies and methodologies.</p> <p><strong>Arena’s mission is to provide truthful and scientific evaluation of models across diverse domains, grounded in real-world uses.</strong> This commitment drives our continuous efforts to refine Arena’s evaluation mechanisms, ensure methodological transparency, and foster trust across the AI ecosystem. We stand by the integrity and transparency of the Chatbot Arena platform. We welcome constructive feedback, especially when it helps us all build better tools for the community. However, it’s crucial that such critiques are based on accurate data and a correct understanding of our publicly stated policies and methodologies.</p> <p>We encourage everyone to review our <a href="https://blog.lmarena.ai/blog/2024/policy/" rel="external nofollow noopener" target="_blank">policy</a>, <a href="https://arxiv.org/abs/2403.04132" rel="external nofollow noopener" target="_blank">research paper</a> and <a href="https://huggingface.co/lmarena-ai" rel="external nofollow noopener" target="_blank">open datasets</a>. Our goal remains to provide a valuable, community-driven resource for LLM evaluation.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"lmarena/lmarena.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 LM Arena. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-",title:"",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-about",title:"about",description:"",section:"Navigation",handler:()=>{window.location.href="/about/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-our-response-to-39-the-leaderboard-illusion-39-writeup",title:"Our Response to &#39;The Leaderboard Illusion&#39; Writeup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/our-response/"}},{id:"post-celebrating-community-impact-3m-votes-400-models-and-300-pre-release-tests",title:"Celebrating Community Impact: 3M+ votes, 400+ models, and 300+ pre-release tests",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/two-year-celebration/"}},{id:"post-does-sentiment-matter-too",title:"Does Sentiment Matter Too?",description:"Introducing Sentiment Control: Disentagling Sentiment and Substance",section:"Posts",handler:()=>{window.location.href="/blog/2025/sentiment-control/"}},{id:"post-how-many-user-prompts-are-new",title:"How Many User Prompts are New?",description:"Analysis of prompt freshness and benchmark contamination",section:"Posts",handler:()=>{window.location.href="/blog/2025/freshness/"}},{id:"post-lmarena-is-growing-to-support-our-community-platform",title:"LMArena is Growing to Support our Community Platform",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/new-beta/"}},{id:"post-introducing-the-search-arena-evaluating-search-enabled-ai",title:"Introducing the Search Arena: Evaluating Search-Enabled AI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/search-arena/"}},{id:"post-lmarena-community-updates-looking-ahead",title:"LMArena Community Updates: Looking Ahead",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/new-discord-server/"}},{id:"post-webdev-arena",title:"WebDev Arena",description:"A Live LLM Leaderboard for Web App Development",section:"Posts",handler:()=>{window.location.href="/blog/2025/webdev-arena/"}},{id:"post-repochat-arena",title:"RepoChat Arena",description:"A Live Benchmark for AI Software Engineers",section:"Posts",handler:()=>{window.location.href="/blog/2025/repochat-arena/"}},{id:"post-arena-explorer",title:"Arena Explorer",description:"A topic modeling pipeline for LLM evals &amp; analytics",section:"Posts",handler:()=>{window.location.href="/blog/2025/arena-explorer/"}},{id:"post-code-editing-in-copilot-arena",title:"Code Editing in Copilot Arena",description:"Copilot Arena&#39;s Code Editing Leaderboard and Insights",section:"Posts",handler:()=>{window.location.href="/blog/2025/copilot-arena-edits/"}},{id:"post-copilot-arena",title:"Copilot Arena",description:"Copilot Arena&#39;s Initial Leaderboard, Insights, and a New Prompting Method for Code Completions",section:"Posts",handler:()=>{window.location.href="/blog/2024/copilot-arena/"}},{id:"post-chatbot-arena-categories",title:"Chatbot Arena Categories",description:"Definitions, Methods, and Insights",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-category/"}},{id:"post-preference-proxy-evaluations",title:"Preference Proxy Evaluations",description:"A New Benchmark for Evaluating Reward Models and LLM Judges",section:"Posts",handler:()=>{window.location.href="/blog/2024/preference-proxy-evaluations/"}},{id:"post-agent-arena",title:"Agent Arena",description:"A Platform for Evaluating and Comparing LLM Agents Across Models, Tools, and Frameworks",section:"Posts",handler:()=>{window.location.href="/blog/2024/agent-arena/"}},{id:"post-statistical-extensions-of-the-bradley-terry-and-elo-models",title:"Statistical Extensions of the Bradley-Terry and Elo Models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/extended-arena/"}},{id:"post-chatbot-arena-new-blog",title:"Chatbot Arena New Blog",description:"A new chapter for Chatbot Arena!",section:"Posts",handler:()=>{window.location.href="/blog/2024/new-site/"}},{id:"post-redteam-arena",title:"RedTeam Arena",description:"An Open-Source, Community-driven Jailbreaking Platform",section:"Posts",handler:()=>{window.location.href="/blog/2024/redteam-arena/"}},{id:"post-does-style-matter",title:"Does Style Matter?",description:"Disentangling style and substance in Chatbot Arena",section:"Posts",handler:()=>{window.location.href="/blog/2024/style-control/"}},{id:"post-the-multimodal-arena-is-here",title:"The Multimodal Arena is Here!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/multimodal/"}},{id:"post-introducing-hard-prompts-category-in-chatbot-arena",title:"Introducing Hard Prompts Category in Chatbot Arena",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/hard-prompts/"}},{id:"post-what-39-s-up-with-llama-3-arena-data-analysis",title:"What&#39;s up with Llama 3? Arena data analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/llama3/"}},{id:"post-lmsys-chatbot-arena-kaggle-competition",title:"LMSYS Chatbot Arena Kaggle Competition",description:"Predicting Human Preference with $100,000 in Prizes",section:"Posts",handler:()=>{window.location.href="/blog/2024/kaggle-competition/"}},{id:"post-from-live-data-to-high-quality-benchmarks-the-arena-hard-pipeline",title:"From Live Data to High-Quality Benchmarks - The Arena-Hard Pipeline",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-hard/"}},{id:"post-chatbot-arena-policy",title:"Chatbot Arena Policy",description:"Live and Community-Driven LLM Evaluation",section:"Posts",handler:()=>{window.location.href="/blog/2024/policy/"}},{id:"post-chatbot-arena-new-models-amp-elo-system-update",title:"Chatbot Arena - New models &amp; Elo system update",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-elo-update/"}},{id:"post-catch-me-if-you-can-how-to-beat-gpt-4-with-a-13b-model",title:"Catch me if you can! How to beat GPT-4 with a 13B model...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/llm-decontaminator/"}},{id:"post-chatbot-arena-conversation-dataset-release",title:"Chatbot Arena Conversation Dataset Release",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/dataset/"}},{id:"post-chatbot-arena-leaderboard-updates-week-8",title:"Chatbot Arena Leaderboard Updates (Week 8)",description:"Introducing MT-Bench and Vicuna-33B",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week8/"}},{id:"post-chatbot-arena-leaderboard-updates-week-4",title:"Chatbot Arena Leaderboard Updates (Week 4)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week4/"}},{id:"post-chatbot-arena-leaderboard-updates-week-2",title:"Chatbot Arena Leaderboard Updates (Week 2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week2/"}},{id:"post-chatbot-arena",title:"Chatbot Arena",description:"Benchmarking LLMs in the Wild with Elo Ratings",section:"Posts",handler:()=>{window.location.href="/blog/2023/arena/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%6D%61%72%65%6E%61.%61%69@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>