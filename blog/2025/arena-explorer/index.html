<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Arena Explorer | LM Arena </title> <meta name="author" content="LM Arena"> <meta name="description" content="A topic modeling pipeline for LLM evals &amp; analytics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/vicuna.jpeg?101e2cca9da6907c55807adf8b3b38b7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lmarena.github.io/blog/2025/arena-explorer/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Arena Explorer",
            "description": "A topic modeling pipeline for LLM evals & analytics",
            "published": "February 11, 2025",
            "authors": [
              
              {
                "author": "Kelly Tang",
                "authorURL": "https://www.linkedin.com/in/kelly-yuguo-tang/",
                "affiliations": [
                  {
                    "name": "UC Berkeley",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Anastasios N. Angelopoulos",
                "authorURL": "http://angelopoulos.ai",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Wei-Lin Chiang",
                "authorURL": "https://infwinston.github.io/",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title" href="/"> <span class="font-weight-bold">LM</span> Arena </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/about/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Arena Explorer</h1> <p>A topic modeling pipeline for LLM evals &amp; analytics</p> </d-title> <d-byline></d-byline> <d-article> <h2 id="introduction">Introduction</h2> <p>Chatbot Arena receives vast amounts of LLM conversations daily. However, understanding what people ask, how they structure prompts, and how models perform isn’t straightforward. Raw text data is messy and complex. Analyzing small samples is feasible, but identifying trends in large datasets is challenging. This isn’t just our problem. Anyone dealing with unstructured data, e.g. long texts and images, faces the same question: how do you organize it to extract meaningful insights?</p> <p>To address this, we developed a topic modeling pipeline and the <strong>Arena Explorer</strong>. This pipeline organizes user prompts into distinct topics, structuring the text data hierarchically to enable intuitive analysis. We believe this tool for hierarchical topic modeling can be valuable to anyone analyzing complex text data.</p> <div class="l-page" style="display: flex; justify-content: center; align-items: center;"> <div style="position: relative; width: 100%; max-width: 1200px; height: 0; padding-bottom: 70%; margin-bottom: 20px"> <iframe src="https://storage.googleapis.com/public-arena-no-cors/index.html" frameborder="0" scrolling="yes" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; background-color: white;" allowfullscreen=""> </iframe> </div> </div> <p>In this blog post, we will cover:</p> <ul> <li>Analysis of LLM performance insights received from Arena Explorer.</li> <li>Details of how we created the Explorer, transforming a large dataset of user conversations into an exploratory tool.</li> <li>Ways to fine-tune and improve topic models.</li> </ul> <p>Check out the pipeline in this <a href="https://colab.research.google.com/drive/1chzqjePYnpq08fA3KzyKvSkuzCjojyiE?usp=sharing" rel="external nofollow noopener" target="_blank">colab notebook</a>, and try it out yourself.</p> <p>We also published the <a href="https://huggingface.co/datasets/lmarena-ai/arena-explorer-preference-100k" rel="external nofollow noopener" target="_blank">dataset</a> we used. This dataset contains 100k leaderboard conversation data, the largest prompt dataset with human preferences we have every released!</p> <h2 id="insights">Insights</h2> <p><strong>Model Performance Comparison</strong></p> <p>In our previous <a href="https://blog.lmarena.ai/blog/2024/arena-category/" rel="external nofollow noopener" target="_blank">blog post</a>, we conducted an in-depth categorical analysis and discussed key insights. That analysis was based on manually defined categories in Chatbot Arena. The results showed that language models perform differently across categories. With our topic modeling pipeline, we can now analyze model performance across categories more efficiently and dive deeper into specific topics.</p> <p>Compared to <em>Tech Programming</em>, model rankings for the other two largest broad categories, <em>Creative Writing</em> and <em>Puzzles &amp; Math</em>, shifted significantly.</p> <div> <iframe src="/assets/img/blog/explorer/rank_broad_cat.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 1. Tech Programming vs. Creative Writing vs. Puzzles Chatbot Arena ranking of the top 10 ranked models in Tech Programming.</p> <p>Claude performed better than Gemini in <em>Tech Programming</em>, while Gemini outperformed Claude in <em>Creative Writing</em>. Deepseek-coder-v2 dropped in ranking for <em>Creative Writing</em> compared to its position in <em>Tech Programming</em>.</p> <div> <iframe src="/assets/img/blog/explorer/rank_tech_vs_writing.html" frameborder="0" scrolling="no" height="800px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 2. Tech Programming vs. Creative Writing Chatbot Arena Score computed using the Bradley-Terry model.</p> <p><strong>Diving into Narrow Categories</strong></p> <p>Model performance analysis can be broken down into more specific categories based on win rates. We calculated the win rates of Gemini 1.5, GPT-4o, and Claude 3.5 across the narrow categories, treating ties as 0.5 wins. Gemini 1.5 performed best in <em>Entrepreneurship and Business Strategy</em> but had a noticeably lower win rate in <em>Songwriting and Playlist Creation</em>. In contrast, GPT-4o maintained a relatively consistent win rate across most categories, except for a dip in <em>Entrepreneurship and Business Strategy</em>. Claude 3.5 excelled in <em>Web Development</em> and <em>Linux &amp; Shell Scripting</em> but had lower win rates in other, less technical categories.</p> <div> <iframe src="/assets/img/blog/explorer/winrate_narrow.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 3. Model win rates in the eight largest narrow categories.</p> <p>Even within the same broad category, model performance varies slightly. For example, within <em>Tech Programming</em>, GPT-4o showed a lower win rate in <em>GPU and CPU Performance and Comparison</em> compared to other categories. Within <em>Creative Writing</em>, Gemini had a significantly higher win rate in <em>Genshin Impact Parody Adventures</em>.</p> <div> <iframe src="/assets/img/blog/explorer/winrate_tech.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 4. Model win rates in the eight largest narrow categories within Tech Programming.</p> <div> <iframe src="/assets/img/blog/explorer/winrate_writing.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 5. Model win rates in the eight largest narrow categories within Creative Writing.</p> <p>Note: Since models compete against different sets of opponents, win rates are only meaningful when compared within the same model. Therefore, we do not directly compare win rates across different models.</p> <h2 id="topic-modeling-pipeline">Topic Modeling Pipeline</h2> <p>We used the leaderboard conversation data between June 2024 and August 2024. To facilitate clustering in later steps, we selected prompts tagged in English and removed duplicate prompts. The final dataset contains around 52k prompts.</p> <p>To group the prompts into narrow categories, we used a topic modeling pipeline with <a href="https://maartengr.github.io/BERTopic/index.html" rel="external nofollow noopener" target="_blank">BERTopic</a>, similar to the one presented in our paper <a href="https://arxiv.org/abs/2403.04132" rel="external nofollow noopener" target="_blank">(Chiang, 2024)</a>. We performed the following steps.</p> <ol> <li>We create embeddings for user prompts with SentenceTransformers’ model (all-mpnet-base-v2), transforming prompts into representation vectors.</li> <li>To reduce the dimensionality of embeddings, we use UMAP (Uniform Manifold Approximation and Projection)</li> <li>We use the density distribution-based clustering algorithm HDBSCAN to identify topic clusters with a minimum clustering size of 20.</li> <li>We select 20 example prompts per cluster. They were chosen from the ones with high HDBSCAN probability scores (top 20% within their respective clusters). For clarity, we choose those with fewer than 100 words.</li> <li>To come up with cluster names, we feed the example prompts into ChatGPT-4o to give the category a name and description.</li> <li>We reduced all outliers using probabilities obtained from HDBSCAN and then embeddings of each outlier prompt. This pipeline groups the prompts into narrow categories, each with 20 example prompts.</li> </ol> <div> <iframe src="/assets/img/blog/explorer/intertopic_distance.html" frameborder="0" scrolling="no" height="700px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 6. The intertropical distance map shows the narrow clusters identified by BERTopic. The size of the circles is proportional to the amount of prompts in the cluster.</p> <p>We consolidate the initial narrow categories into broad categories for more efficient and intuitive exploration. We perform a second round of this topic modeling pipeline on the summarized category names and descriptions generated earlier. The steps are almost identical to before. Except for steps 4 and 5, we use all category names in a cluster for summarization instead of selecting examples.</p> <h3 id="tuning-topic-clusters">Tuning Topic Clusters</h3> <p>Topic clusters are not always accurate. Some prompts may not be placed in the most suitable cluster, and the same applies to specific categories. Many factors influence the final clustering:</p> <ol> <li>Embedding models used to generate vector representations for prompts</li> <li>Sampled example prompts used to assign cluster names</li> <li>BERTopic model parameters that affect the number of clusters, such as n_neighbors in UMAP and min_cluster_size in HDBSCAN</li> <li>Outlier reduction methods</li> </ol> <p><strong>How do we improve and fine-tune the clusters?</strong> Embedding models play a major role in clustering accuracy since they are used to train the clustering model. We compared two models on a 10k sample dataset: Sentence Transformer’s all-mpnet-base-v2 and OpenAI’s text-embedding-3-large, a more recent model. According to the <a href="https://huggingface.co/spaces/mteb/leaderboard" rel="external nofollow noopener" target="_blank">MTEB Leaderboard</a>, text-embedding-3-large performs better on average (57.77). The clustering results are noticeably different.</p> <p>With text-embedding-3-large, the broad category distribution is more balanced. In contrast, all-mpnet-base-v2 produced a large <em>Tech Programming</em> category. Zooming in on this category, we found that AI-related clusters were merged into <em>Tech Programming</em> when using all-mpnet-base-v2, whereas text-embedding-3-large formed a separate AI-related category. Choosing which result to use depends on human preference.</p> <div class="l-page" style="display: flex; justify-content: center; align-items: center;"> <iframe src="/assets/img/blog/explorer/embedding_mpnet_broad.html" frameborder="0" scrolling="no" height="700px" width="100%"></iframe> <iframe src="/assets/img/blog/explorer/embedding_mpnet_tech.html" frameborder="0" scrolling="no" height="700px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 7 &amp; 8. Broad categories and specific categories in “Tech Programming” summarized using all-mpnet-base-v2.</p> <div class="l-page" style="display: flex; justify-content: center; align-items: center;"> <iframe src="/assets/img/blog/explorer/embedding_openai_broad.html" frameborder="0" scrolling="no" height="700px" width="100%"></iframe> <iframe src="/assets/img/blog/explorer/embedding_openai_tech.html" frameborder="0" scrolling="no" height="700px" width="100%"></iframe> </div> <p style="color:gray; text-align: center;">Figure 9 &amp; 10. Broad categories and specific categories in “Tech Programming” summarized using text-embedding-3-large.</p> <p>Beyond embedding models, adjusting parameters and outlier reduction methods helps refine the clusters. For example, we increased the min_cluster_size parameter to adjust the broad clusters. Before, several broad categories had similar meanings. By increasing this parameter, we reduced the number of clusters, resulting in more distinctive categories.</p> <h2 id="whats-next">What’s next?</h2> <p>We will add more features to our explorer that provide insights into the connection between model performance and prompt category, such as model performance per category.</p> <p>We would love to hear your feedback and how you are using the pipeline to derive insights!</p> <h2 id="citation">Citation</h2> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">tang2025explorer</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{Arena Explorer: A Topic Modeling Pipeline for LLM Evals &amp; Analytics}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Kelly Tang and Wei-Lin Chiang and Anastasios N. Angelopoulos}</span>
    <span class="nv">year</span><span class="err">={2025</span><span class="p">}</span><span class="c">,</span>
<span class="c">}</span>

<span class="nc">@misc</span><span class="p">{</span><span class="nl">chiang2024chatbot</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
    <span class="na">eprint</span><span class="p">=</span><span class="s">{2403.04132}</span><span class="p">,</span>
    <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
    <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.AI}</span>
<span class="p">}</span>
</code></pre></div></div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"lmarena/lmarena.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 LM Arena. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-",title:"",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-about",title:"about",description:"",section:"Navigation",handler:()=>{window.location.href="/about/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-our-response-to-39-the-leaderboard-illusion-39-writeup",title:"Our Response to &#39;The Leaderboard Illusion&#39; Writeup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/our-response/"}},{id:"post-celebrating-community-impact-3m-votes-400-models-and-300-pre-release-tests",title:"Celebrating Community Impact: 3M+ votes, 400+ models, and 300+ pre-release tests",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/two-year-celebration/"}},{id:"post-does-sentiment-matter-too",title:"Does Sentiment Matter Too?",description:"Introducing Sentiment Control: Disentagling Sentiment and Substance",section:"Posts",handler:()=>{window.location.href="/blog/2025/sentiment-control/"}},{id:"post-how-many-user-prompts-are-new",title:"How Many User Prompts are New?",description:"Analysis of prompt freshness and benchmark contamination",section:"Posts",handler:()=>{window.location.href="/blog/2025/freshness/"}},{id:"post-lmarena-is-growing-to-support-our-community-platform",title:"LMArena is Growing to Support our Community Platform",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/new-beta/"}},{id:"post-introducing-the-search-arena-evaluating-search-enabled-ai",title:"Introducing the Search Arena: Evaluating Search-Enabled AI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/search-arena/"}},{id:"post-lmarena-community-updates-looking-ahead",title:"LMArena Community Updates: Looking Ahead",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/new-discord-server/"}},{id:"post-webdev-arena",title:"WebDev Arena",description:"A Live LLM Leaderboard for Web App Development",section:"Posts",handler:()=>{window.location.href="/blog/2025/webdev-arena/"}},{id:"post-repochat-arena",title:"RepoChat Arena",description:"A Live Benchmark for AI Software Engineers",section:"Posts",handler:()=>{window.location.href="/blog/2025/repochat-arena/"}},{id:"post-arena-explorer",title:"Arena Explorer",description:"A topic modeling pipeline for LLM evals &amp; analytics",section:"Posts",handler:()=>{window.location.href="/blog/2025/arena-explorer/"}},{id:"post-code-editing-in-copilot-arena",title:"Code Editing in Copilot Arena",description:"Copilot Arena&#39;s Code Editing Leaderboard and Insights",section:"Posts",handler:()=>{window.location.href="/blog/2025/copilot-arena-edits/"}},{id:"post-copilot-arena",title:"Copilot Arena",description:"Copilot Arena&#39;s Initial Leaderboard, Insights, and a New Prompting Method for Code Completions",section:"Posts",handler:()=>{window.location.href="/blog/2024/copilot-arena/"}},{id:"post-chatbot-arena-categories",title:"Chatbot Arena Categories",description:"Definitions, Methods, and Insights",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-category/"}},{id:"post-preference-proxy-evaluations",title:"Preference Proxy Evaluations",description:"A New Benchmark for Evaluating Reward Models and LLM Judges",section:"Posts",handler:()=>{window.location.href="/blog/2024/preference-proxy-evaluations/"}},{id:"post-agent-arena",title:"Agent Arena",description:"A Platform for Evaluating and Comparing LLM Agents Across Models, Tools, and Frameworks",section:"Posts",handler:()=>{window.location.href="/blog/2024/agent-arena/"}},{id:"post-statistical-extensions-of-the-bradley-terry-and-elo-models",title:"Statistical Extensions of the Bradley-Terry and Elo Models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/extended-arena/"}},{id:"post-chatbot-arena-new-blog",title:"Chatbot Arena New Blog",description:"A new chapter for Chatbot Arena!",section:"Posts",handler:()=>{window.location.href="/blog/2024/new-site/"}},{id:"post-redteam-arena",title:"RedTeam Arena",description:"An Open-Source, Community-driven Jailbreaking Platform",section:"Posts",handler:()=>{window.location.href="/blog/2024/redteam-arena/"}},{id:"post-does-style-matter",title:"Does Style Matter?",description:"Disentangling style and substance in Chatbot Arena",section:"Posts",handler:()=>{window.location.href="/blog/2024/style-control/"}},{id:"post-the-multimodal-arena-is-here",title:"The Multimodal Arena is Here!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/multimodal/"}},{id:"post-introducing-hard-prompts-category-in-chatbot-arena",title:"Introducing Hard Prompts Category in Chatbot Arena",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/hard-prompts/"}},{id:"post-what-39-s-up-with-llama-3-arena-data-analysis",title:"What&#39;s up with Llama 3? Arena data analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/llama3/"}},{id:"post-lmsys-chatbot-arena-kaggle-competition",title:"LMSYS Chatbot Arena Kaggle Competition",description:"Predicting Human Preference with $100,000 in Prizes",section:"Posts",handler:()=>{window.location.href="/blog/2024/kaggle-competition/"}},{id:"post-from-live-data-to-high-quality-benchmarks-the-arena-hard-pipeline",title:"From Live Data to High-Quality Benchmarks - The Arena-Hard Pipeline",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/arena-hard/"}},{id:"post-chatbot-arena-policy",title:"Chatbot Arena Policy",description:"Live and Community-Driven LLM Evaluation",section:"Posts",handler:()=>{window.location.href="/blog/2024/policy/"}},{id:"post-chatbot-arena-new-models-amp-elo-system-update",title:"Chatbot Arena - New models &amp; Elo system update",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-elo-update/"}},{id:"post-catch-me-if-you-can-how-to-beat-gpt-4-with-a-13b-model",title:"Catch me if you can! How to beat GPT-4 with a 13B model...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/llm-decontaminator/"}},{id:"post-chatbot-arena-conversation-dataset-release",title:"Chatbot Arena Conversation Dataset Release",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/dataset/"}},{id:"post-chatbot-arena-leaderboard-updates-week-8",title:"Chatbot Arena Leaderboard Updates (Week 8)",description:"Introducing MT-Bench and Vicuna-33B",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week8/"}},{id:"post-chatbot-arena-leaderboard-updates-week-4",title:"Chatbot Arena Leaderboard Updates (Week 4)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week4/"}},{id:"post-chatbot-arena-leaderboard-updates-week-2",title:"Chatbot Arena Leaderboard Updates (Week 2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/leaderboard-week2/"}},{id:"post-chatbot-arena",title:"Chatbot Arena",description:"Benchmarking LLMs in the Wild with Elo Ratings",section:"Posts",handler:()=>{window.location.href="/blog/2023/arena/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%6F%6E%74%61%63%74@%6C%6D%61%72%65%6E%61.%61%69","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>